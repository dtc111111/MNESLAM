dataset: 'indoor'

data:
  depth_filter:
    enable: True
    inpaint_holes: True

  downsample: 1
  sc_factor: 1
  translation: 0
  num_workers: 4
  trainskip: 1

mapping:
  sample: 2048
  first_mesh: False
  iters: 100 #10
  loop_iters: 100
  distill_iters: 50
  cur_frame_iters: 0
  lr_embed: 0.01
  lr_embed_color: 0.01
  lr_decoder: 0.01
  lr_rot: 0.001
  lr_trans: 0.001
  keyframe_every: 5
  map_every: 5
  n_pixels: 0.05
  first_iters: 500
  optim_cur: True
  min_pixels_cur: 100
  map_accum_step: 1
  pose_accum_step: 2
  map_wait_step: 0
  filter_depth: False
#  w_sdf_fs: 20  #10
#  w_sdf_center: 1200
#  w_sdf_tail: 120

  w_sdf_fs: 10
  w_sdf_center: 200
  w_sdf_tail: 50
  vis: 10

tracking:
  pretrained: output/pretrained/droid.pth
  device: "cuda:0"
  buffer: 512
  beta: 0.75
  warmup: 8
  upsample: True
  motion_filter:
    thresh: 4  # add as keyframe if avg flow >= 4.0 pixels##########################33
  backend:
    thresh: 25.0  # only consider edge with avg flow < 25.0 pixels
    radius: 1
    nms: 5
    # used for loop detection
    loop_window: 25  # 50
    loop_thresh: 25.0  # only consider edge with avg flow < 50.0 pixels
    loop_radius: 1
    loop_nms: 12
  frontend:
    enable_loop: True
    keyframe_thresh: 4  # remove keyframe if avg flow < 4.0 pixels##############################3
    thresh: 16.0  # only consider edge with avg flow < 16.0 pixels
    window: 25  # local ba window size
    radius: 1
    nms: 1
    max_factors: 75  # num of edges within local ba

  ignore_edge_W: 20
  ignore_edge_H: 20

  w_sdf_fs: 10
  w_sdf_center: 200
  w_sdf_tail: 50

  iter_point: 0
  sample: 1024
  pc_samples: 40960
  lr_rot: 0.001
  lr_trans: 0.001
  wait_iters: 100
  const_speed: True
  best: True
  iter: 50

grid:
  enc: 'HashGrid'

  hash_size: 16
  voxel_color: 0.08
  voxel_sdf: 0.02
  oneGrid: True

pos:
  enc: 'OneBlob'
  n_bins: 16

decoder:
  geo_feat_dim: 15
  hidden_dim: 32
  num_layers: 2
  num_layers_color: 2
  hidden_dim_color: 32
  tcnn_network: False

cam:
  ### original camera parameters
  H: 720
  W: 1280
  fx: 637.147
  fy: 636.668
  cx: 637.003
  cy: 363.032
  png_depth_scale: 1000.0 #for depth image in png format
  ### target/output camera settings, camera_size -> resize -> crop -> target_size
  H_edge: 8
  W_edge: 8
  H_out: 360
  W_out: 640
#  H: 720
#  W: 1280
#  fx: 637.146728515625
#  fy: 636.6676025390625
#  cx: 637.002685546875
#  cy: 363.0322265625

#  png_depth_scale: 1000. #for depth image in png format
  crop_edge: 0
  near: 0
  far: 60.0
  depth_trunc: 100.

training:
  rgb_weight: 5.0
  depth_weight: 0.1
  sdf_weight: 1000
  fs_weight: 10
  eikonal_weight: 0
  smooth_weight: 0.001
  smooth_pts: 64
  smooth_vox: 0.1
  smooth_margin: 0.05
  n_samples: 512
  n_samples_d: 1024
  n_samples_extended: 0
  range_d: 0.2
  n_range_d: 21
  n_importance: 0
  perturb: 1
  white_bkgd: False
  trunc: 0.1
  rot_rep: 'axis_angle'
  rgb_missing: 0.0

distillation:
  use_bound_overlap: True # 是否启用基于边界的重叠区域蒸馏


loop_closure:
  # 在图优化中，为位姿调整引入基于空间距离的权重衰减
  pose_decay_sigma: 5.0 # 权重衰减的高斯核标准差（米）。值越大，影响范围越广。
  pose_decay_min_weight: 0.1 # 即使是距离最远的帧，也施加的最小调整权重，以保证图的连通性。

  # Weights for near vs far points, based on user's idea
  far_plane_threshold: 10.0 # meters, points beyond this are "far"
  near_rgb_weight: 1.0      # Emphasize near points for color detail
  far_rgb_weight: 0.5
  near_depth_weight: 1.0    # Emphasize near points for depth detail
  far_depth_weight: 0.5
  near_sdf_weight: 0.5
  far_sdf_weight: 1.0       # Emphasize far points for geometric structure

#coslam
mesh:
  resolution: 512
  render_color: False
  vis: 100
  voxel_eval: 0.05
  voxel_final: 0.03
  visualisation: False
 #eslam
meshing:
  level_set: 0
  resolution: 0.03 #cm # Increase this number to speed up meshing algorithm
  eval_rec: False
  mesh_bound_scale: 1.02

loop_bound:
  bound_0: [[-6.2,20],[-15.8,0],[-1.0, 4.5]]
  bound_1: [[-6.2,56.4],[-15.8,-7.],[-1.0, 4.5]]
  bound_2: [[25.,56.4],[-13.5,-2.],[-2.0, 4.5]]
  bound_3: [[-6.2,50.],[-6.5,-2.2],[-2.0, 4.5]]

distillation:
  use_bound_overlap: True

model_name: 'VGG16-NetVLAD-Pitts30K'

checkpoints:
  VGG16-NetVLAD-Pitts30K: 'output/VGG16-NetVLAD-Pitts30K.mat'
  VGG16-NetVLAD-TokyoTM: 'output/VGG16-NetVLAD-TokyoTM.mat'